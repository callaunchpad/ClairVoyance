{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Beauty and Joy of Tensorflow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This tutorial will give you a low level look into how tensorflow operates so you feel comfortable with the API\\nand you will run through a basic NN tutorial. From there you should be able to pick up future models and use them with\\ntensorflow functions. This is also assuming you understand basic NN (you can check the education doc to review if needed).'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"This tutorial will give you a low level look into how tensorflow operates so you feel comfortable with the API\n",
    "and you will run through a basic NN tutorial. From there you should be able to pick up future models and use them with\n",
    "tensorflow functions. This is also assuming you understand basic NN (you can check the education doc to review if needed).\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we need to import tensorflow and helper libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "%matplotlib inline \n",
    "#For some reason this is necessary on jupyter notebook idk why\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Sweet! Now what? Well first let's start by \n",
    "importing the mother of all ML data: MNIST. We will use for our example for a basic NN.\n",
    "We will import the dataset from keras and load in the training the testing separately\"\"\"\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "#Here Keras automatically splits our dataset into training and testing along with inputs and labels. Let's see what they look like\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of our training input: (60000, 28, 28)\n",
      "shape of our training labels: (60000,)\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "#Let's see what the shape of our data looks like\n",
    "print(\"shape of our training input: {}\".format(x_train.shape))\n",
    "print(\"shape of our training labels: {}\".format(y_train.shape))\n",
    "print(x_train[0])\n",
    "#print(y_train[0])#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Find a way to check which number the image x_train[0] represents without seeing the image itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"So we have 60,000 training examples (which is a lot!). But I want to see the digits themselves!\n",
    "This is where we can use some matplotlib, which will be useful when we want to check say our weather images\n",
    "predictions\"\"\"\n",
    "plt.imshow(x_train[3])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Looks like a 1! There are other ways to display images with PIL and Scipy \n",
    "but MatPlotLib tends to have more features. Ok but something to notice is that the labels are normal digits.\n",
    "Usually when have a neural model for classification, it will output a vector of probabilities for each category\n",
    "EX with 5 categories: [0.01, 0.12, 0.84, 0.0, 0.03]\n",
    "Because of this, we want our labels themselves to be a vector of probabilites to train the model with.\n",
    "EX if label is 2: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0] since ideally we want the 100% probability for category 2 and 0 elsewhere\n",
    "In order to do this we do an operation called one_hot.\"\"\"\n",
    "\n",
    "numpy_zero = np.zeros((y_train.shape[0], 10))\n",
    "numpy_zero[np.arange(y_train.shape[0]), y_train] = 1\n",
    "y_train = numpy_zero #TODO: one-hot both y_train and y_test using numpy operations (You can search up how to do this)\n",
    "numpy_zero2 = np.zeros((y_test.shape[0], 10))\n",
    "numpy_zero2[np.arange(y_test.shape[0]), y_test] = 1\n",
    "y_test = numpy_zero2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "'Ok Pardhu this is great and all but I came here to learn tensorflow, not look at handwritten digits'\n",
    "Alright well I won't hold you off any longer! Let's get into what a tensorflow model will look like.\n",
    "While Arsh will have a more complete workshop on tensorflow, there are two important stages to building\n",
    "a model on tensorflow.\n",
    "1. Define the abstract graph of the model along with all important variables inside the graph and how it will train.\n",
    "2. Open up a tensorflow session to then feed in the inputs and train over epochs\n",
    "Let's start with part one and see how that looks:\n",
    "\"\"\"\n",
    "#Define our model through a function:\n",
    "def ourModel(inputs):\n",
    "    #We assume the shape of inputs is [None, 784]. None represents number of images and is variable. (But why 784?).\n",
    "    #Let's create our first neural layer that create a [None, 128] matrix from the inputs matrix.\n",
    "    first_layer = tf.layers.dense(inputs=inputs, units=128)\n",
    "    \n",
    "    #But wait! The whole point of neural networks is our activation function. Let's use relu in the next line.\n",
    "    #If confused why, check out https://www.analyticsvidhya.com/blog/2017/10/fundamentals-deep-learning-activation-functions-when-to-use-them/\n",
    "    first_layer = tf.nn.relu(first_layer)\n",
    "    \n",
    "    #And that's it! Though it seems a bit unclean to have separate lines like that. Let's simplify for the next layer\n",
    "    second_layer = tf.layers.dense(inputs=first_layer, units=64, activation=tf.nn.relu)\n",
    "    \"\"\"Sweet! We have two layers that each have relu activation functions.\n",
    "    TODO: Now it is up to you to finish the model. Add one more hidden layer with 32 units and then the output layer\"\"\"\n",
    "    \n",
    "    third_layer = tf.layers.dense(inputs=second_layer, units=32, activation=tf.nn.relu)\n",
    "    \n",
    "    \n",
    "    output_layer = tf.layers.dense(inputs=third_layer, units=10, activation=tf.nn.softmax)\n",
    "    \n",
    "    \"\"\"NOTE: We want our output layer to be of size [None, 10] since there are 10 digits and we can use the vector as\n",
    "    a probability output. But we want the probability to be between 0 to 1 which relu doesn't do. What other activation\n",
    "    funciton can we use?\"\"\"\n",
    "    return output_layer\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-7e7f56200513>:14: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /Users/pardhuk/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x62c8cff60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x62c8cff60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x62c8cff60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x62c8cff60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x626a48fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x626a48fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x626a48fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x626a48fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x626a48fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x626a48fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x626a48fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x626a48fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x626a48fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x626a48fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x626a48fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x626a48fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From <ipython-input-10-8b56fc8181c8>:18: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Here we have defined the operation of our model through a function. But this isn't actually where we create\n",
    "the tensorflow graph. We can do that right below like a normal python script. The important thing is that this\n",
    "is recognized as a graph model for tf because our operations are done on what we define as tf placeholders\n",
    "\"\"\"\n",
    "inputs=tf.placeholder(tf.float32, shape=[None, 784])\n",
    "#Because normal dense layers take in 1D data to connect to each neuron, we can't feed in the image as a 2D matrix.\n",
    "#Instead for each image we will feed in each pixel: 28x28 = 784\n",
    "labels = tf.placeholder(tf.float32, shape=[None, 10]) #TODO: Make a placeholder for the labels which will be a vector of size 10 for each image.\n",
    "\n",
    "#Now we can create the abstract graph by essentially using these placeholders. NOTHING runs in the following lines.\n",
    "#All that happens is tf will use the placeholder shapes to then create space based on the defined model, so that each\n",
    "#step has defined tensor shapes\n",
    "outputs = ourModel(inputs)\n",
    "\n",
    "#That was easy!\n",
    "#Ok now let's define our loss and how we will train it. It's ok if you don't understand these specific loss functions\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=outputs, labels=labels))\n",
    "\n",
    "#And now we have to optimize this loss\n",
    "trainer = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss)\n",
    "\n",
    "#Let's also define accuracy for our viewing\n",
    "_, accuracy = tf.metrics.accuracy(tf.argmax(labels, 1), tf.argmax(outputs, 1))\n",
    "\n",
    "#Let's set some hyperparamaters for batch size and epochs\n",
    "batch_size = 128\n",
    "num_epochs = 10\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We have constructed our model! Now let's move on to actually training it. This is where we have to run\n",
    "a tensorflow session in the following way\n",
    "\"\"\"\n",
    "#First let's scale the values from [0, 255] to [0, 1]\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0 \n",
    "x_train = np.reshape(x_train, [-1, 784]) #TODO: keep reading until sess.run then uncomment and finish this. There are many ways of doing this but look into a reshape operation in numpy\n",
    "x_test = np.reshape(x_test, [-1, 784])\n",
    "\n",
    "init=tf.global_variables_initializer() #initializer of all variables (The random weights of the model before training).\n",
    "local_init = tf.local_variables_initializer() #This isn't always needed but tf.metrics.accuracy has local variables to initialize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to run session...\n",
      "Accuracy at epoch 0 is [0.87]\n",
      "Accuracy at epoch 1 is [0.8831053]\n",
      "Accuracy at epoch 2 is [0.8808889]\n",
      "Accuracy at epoch 3 is [0.8869412]\n",
      "Accuracy at epoch 4 is [0.889825]\n",
      "Accuracy at epoch 5 is [0.8920444]\n",
      "Accuracy at epoch 6 is [0.89410204]\n",
      "Accuracy at epoch 7 is [0.89378846]\n",
      "Accuracy at epoch 8 is [0.89275926]\n",
      "Accuracy at epoch 9 is [0.8918545]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    #each call to sess.run() runs the approriate input within our tf session\n",
    "    sess.run(init)\n",
    "    sess.run(local_init)\n",
    "    print(\"Starting to run session...\")\n",
    "    for epoch in range(num_epochs): #iterate through each epoch\n",
    "        for i in range(x_train.shape[0]//batch_size): #iterate through the number of batches we can make from our samples\n",
    "            batch_images = x_train[i*batch_size:(i+1)*batch_size]\n",
    "            batch_labels = y_train[i*batch_size:(i+1)*batch_size]\n",
    "            #We have a batch of training images and labels. \n",
    "            #Now we need to run the model by inputing these into the place holders we made\n",
    "            _ = sess.run([trainer], feed_dict={inputs: batch_images, labels: batch_labels})\n",
    "            \"\"\"The output of sess.run will be the variable in the first input array. Essentially, the model will run\n",
    "            up until that variable and feeding in to the corresponding placeholders in feed_dict.\n",
    "            By having trainer has an output variable, we ensure that the model is run until the trainer which means\n",
    "            the model will work to minimize loss\n",
    "            #NOTE: The above line will error out. Why? Because we defined inputs with shape [None, 784]\n",
    "            #But we are feeding in something of shape [None, 28, 28]. How can we fix this? (Look at above TODO now).\"\"\"\n",
    "            \n",
    "        \"\"\"Once you have that fixed, we are done! Our model will train on its own\n",
    "        TODO: Ok but I want to see how well the model is doing. Here, for each epoch, let's feed in testing images\n",
    "        and print out the accuracy as we defined above. For each epoch test a different segment of test data (similar to\n",
    "        what we did in the batching).\n",
    "        NOTE: If you run into an error where your accuracy is outputting something involving <Tensor...>, \n",
    "        make sure the variable you are using to store your accuracy is NOT 'accuracy'. Tensorflow, unfortunately, will not store them separately \n",
    "        and will confused 'accuracy' with the one defined in the graph\"\"\"\n",
    "        size = x_test.shape[0]//num_epochs\n",
    "        test_images = x_test[epoch*size:(i+1)*size]\n",
    "        test_labels = y_test[epoch*size:(i+1)*size]\n",
    "        test_accuracy = sess.run([accuracy], feed_dict = {inputs: test_images, labels: test_labels})\n",
    "        print(\"Accuracy at epoch {} is {}\".format(epoch, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
